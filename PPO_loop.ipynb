{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-25.1.1\n",
      "\u001b[31mERROR: Ignored the following yanked versions: 0.3.0a0\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchdata==0.5.1 (from versions: 0.3.0a1, 0.3.0, 0.6.0, 0.6.1, 0.7.0, 0.7.1, 0.8.0, 0.9.0, 0.10.0, 0.10.1, 0.11.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchdata==0.5.1\u001b[0m\u001b[31m\n",
      "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m183.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m176.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m194.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33m  DEPRECATION: Building 'rouge_score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge_score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [peft]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Collecting git+https://github.com/lvwerra/trl.git@25fa1bd\n",
      "  Cloning https://github.com/lvwerra/trl.git (to revision 25fa1bd) to /tmp/pip-req-build-p_g76krf\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/lvwerra/trl.git /tmp/pip-req-build-p_g76krf\n",
      "\u001b[33m  WARNING: Did not find branch or tag '25fa1bd', assuming revision or ref.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running command git checkout -q 25fa1bd\n",
      "  Resolved https://github.com/lvwerra/trl.git to commit 25fa1bd\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.4.2.dev0) (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.4.2.dev0) (4.27.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.11/dist-packages (from trl==0.4.2.dev0) (2.0.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from trl==0.4.2.dev0) (1.7.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from trl==0.4.2.dev0) (2.14.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.4.2.dev0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.4.0->trl==0.4.2.dev0) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (0.33.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.18.0->trl==0.4.2.dev0) (1.1.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->trl==0.4.2.dev0) (5.9.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate->trl==0.4.2.dev0) (0.5.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.4.2.dev0) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.4.2.dev0) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.4.2.dev0) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.4.2.dev0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.4.2.dev0) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.4.2.dev0) (3.11.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.4.2.dev0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.4.2.dev0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.4.2.dev0) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.4.2.dev0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets->trl==0.4.2.dev0) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->trl==0.4.2.dev0) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.4.2.dev0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.4.2.dev0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.4.2.dev0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.4.2.dev0) (1.17.0)\n",
      "Building wheels for collected packages: trl\n",
      "\u001b[33m  DEPRECATION: Building 'trl' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'trl'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for trl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for trl: filename=trl-0.4.2.dev0-py3-none-any.whl size=67531 sha256=f29d9851eb7c855e75b74c91464c6aa6d1a6d958c51afe9403085820a2aea977\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-k47aiztf/wheels/86/18/04/caa0546abb76d4ef9567e08843952f41f06f867dd864d76aea\n",
      "Successfully built trl\n",
      "Installing collected packages: trl\n",
      "Successfully installed trl-0.4.2.dev0\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch==1.13.1 \\\n",
    "    torchdata==0.5.1 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers==4.27.2 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    rouge_score==0.1.2 \\\n",
    "    peft==0.3.0 --quiet\n",
    "%pip install datasets\n",
    "# Installing the Reinforcement Learning library directly from github.\n",
    "%pip install git+https://github.com/lvwerra/trl.git@25fa1bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Installing collected packages: fsspec, datasets\n",
      "\u001b[2K  Attempting uninstall: fsspec\n",
      "\u001b[2K    Found existing installation: fsspec 2025.3.2\n",
      "\u001b[2K    Uninstalling fsspec-2025.3.2:\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.3.2\n",
      "\u001b[2K  Attempting uninstall: datasets\n",
      "\u001b[2K    Found existing installation: datasets 2.14.4\n",
      "\u001b[2K    Uninstalling datasets-2.14.4:\n",
      "\u001b[2K      Successfully uninstalled datasets-2.14.4\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [datasets]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "432990245b6047318b32cf9d5d931646",
       "pip_warning": {
        "packages": [
         "datasets",
         "fsspec"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForSeq2SeqLMWithValueHead, create_reference_model\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from trl.core import LengthSampler\n",
    "import torch\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e886c4a2bb5453a95d87daaf3af86e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv:   0%|          | 0.00/11.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad82954eff1e49e2824b02043ff0053f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.csv:   0%|          | 0.00/442k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63729e77335745009b60f9201db65e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.csv:   0%|          | 0.00/1.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4906a3146c7a401b80fe21b628d71033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6e6675a9b0419cb7cdea9ecd30108c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c789dfdff9e4a5cbd865bda3ec6cb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50078bb1f94e4d08804b2da74646315c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e2888bee404f3ea6409ccf5c9e307e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3feac5113d4a5d885e61ad5822113f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d33ccb42484d068168169504fbea0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a48c4c143a489295a085f1e6011314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7038656eb0b042dbaba4fcd67c7cbee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10022 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 8017\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'dialogue', 'summary', 'topic', 'input_ids', 'query'],\n",
      "        num_rows: 2005\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(model_name, dataset_name, min_len, max_len):\n",
    "    dataset = load_dataset(dataset_name, split=\"train\")\n",
    "    dataset = dataset.filter(lambda x: min_len < len(x[\"dialogue\"]) <= max_len, batched=False)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def tokenize(sample):\n",
    "        prompt = f\"Summarize the following conversation.\\n\\n{sample['dialogue']}\\n\\nSummary:\\n\"\n",
    "        sample[\"input_ids\"] = tokenizer.encode(prompt, truncation=True, max_length=512) #creates token IDs for words\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"]) #revert that back to original prompt text\n",
    "        return sample\n",
    "\n",
    "    dataset = dataset.map(tokenize, batched=False)\n",
    "    dataset.set_format(type=\"torch\")\n",
    "    return dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "model_name = \"google/flan-t5-base\"\n",
    "dataset = build_dataset(model_name, \"knkarthick/dialogsum\", 200, 1000)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8e2941fb9046c98bb2041fd3cfca8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654213af049b4394805ad8cc8ee66abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fe8c858b8249c69d4b65bf54d5b4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "peft_model = get_peft_model(base_model, lora_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ppo_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(peft_model, is_trainable=True, torch_dtype=torch.bfloat16)\n",
    "\n",
    "ref_model = create_reference_model(ppo_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "reward_model_raw = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "reward_tokenizer = AutoTokenizer.from_pretrained(reward_model_raw, device_map=\"auto\")\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(reward_model_raw, device_map=\"auto\")\n",
    "\n",
    "\n",
    "reward_pipe = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=reward_model,\n",
    "    tokenizer=reward_model,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    "    framework=\"pt\"  \n",
    ")\n",
    "\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None,\n",
    "    \"function_to_apply\": \"none\",\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "not_hate_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(data):\n",
    "    return {key: [d[key] for d in data] for key in data[0]}\n",
    "\n",
    "ppo_config = PPOConfig(\n",
    "    model_name=model_name,\n",
    "    learning_rate=1.41e-5,\n",
    "    ppo_epochs=1,\n",
    "    mini_batch_size=4,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "ppo_trainer = PPOTrainer(config=ppo_config, model=ppo_model, ref_model=ref_model,\n",
    "                         tokenizer=tokenizer, dataset=dataset[\"train\"], data_collator=collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits [not hate, hate]: [3.114102363586426, -2.489619016647339]\n",
      "probabilities [not hate, hate]: [0.9963293671607971, 0.0036706042010337114]\n",
      "reward (high): [3.114102363586426]\n",
      "logits [not hate, hate]: [-0.6921166181564331, 0.3722708821296692]\n",
      "probabilities [not hate, hate]: [0.2564719021320343, 0.7435281276702881]\n",
      "reward (low): [-0.6921166181564331]\n"
     ]
    }
   ],
   "source": [
    "non_toxic_text = \"#Person 1# tells Tommy that he didn't like the movie.\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "reward_model.to(device)\n",
    "\n",
    "toxicity_input = reward_tokenizer(non_toxic_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "logits = reward_model(**toxicity_input).logits\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "\n",
    "not_hate_index = 0\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
    "print(f'reward (high): {nothate_reward}')\n",
    "\n",
    "\n",
    "toxic_text = \"#Person 1# tells Tommy that the movie was terrible, dumb and stupid.\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "reward_model.to(device)\n",
    "toxicity_input = reward_tokenizer(toxic_text, return_tensors=\"pt\").to(device)\n",
    "logits = reward_model(**toxicity_input).logits\n",
    "print(f'logits [not hate, hate]: {logits.tolist()[0]}')\n",
    "probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "print(f'probabilities [not hate, hate]: {probabilities}')\n",
    "not_hate_index = 0  # usually class 0 = \"not hate\"\n",
    "nothate_reward = (logits[:, not_hate_index]).tolist()\n",
    "print(f'reward (low): {nothate_reward}')\n",
    "\n",
    "\n",
    "# Higher reward = less toxic text\n",
    "# Lower reward = more toxic text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward model output:\n",
      "For non-toxic text:\n",
      "[{'label': 'nothate', 'score': 3.114102363586426}, {'label': 'hate', 'score': -2.489619016647339}]\n",
      "[{'label': 'nothate', 'score': 0.9963293671607971}, {'label': 'hate', 'score': 0.0036706042010337114}]\n",
      "For toxic text:\n",
      "[{'label': 'hate', 'score': 0.3722708821296692}, {'label': 'nothate', 'score': -0.6921166181564331}]\n",
      "[{'label': 'hate', 'score': 0.7435281276702881}, {'label': 'nothate', 'score': 0.2564719021320343}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:18<05:50, 18.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "  KL Divergence        : 0.0029426664113998413\n",
      "  Mean Return (Reward) : 1.6667838096618652\n",
      "  Advantage Mean       : -2.2025901103006618e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 10%|█         | 2/20 [00:33<04:54, 16.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2\n",
      "  KL Divergence        : 0.0022393250837922096\n",
      "  Mean Return (Reward) : 1.9268946647644043\n",
      "  Advantage Mean       : 1.3280663679893223e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 15%|█▌        | 3/20 [00:49<04:38, 16.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3\n",
      "  KL Divergence        : 4.531070590019226e-05\n",
      "  Mean Return (Reward) : 1.6874210834503174\n",
      "  Advantage Mean       : -8.114245986234891e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 20%|██        | 4/20 [01:02<04:00, 15.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4\n",
      "  KL Divergence        : -0.012180522084236145\n",
      "  Mean Return (Reward) : 1.9798312187194824\n",
      "  Advantage Mean       : -3.107387769318848e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 25%|██▌       | 5/20 [01:18<03:47, 15.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5\n",
      "  KL Divergence        : 0.009288851171731949\n",
      "  Mean Return (Reward) : 2.101046562194824\n",
      "  Advantage Mean       : 9.610049289676681e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|███       | 6/20 [01:34<03:36, 15.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6\n",
      "  KL Divergence        : -0.01514587551355362\n",
      "  Mean Return (Reward) : 1.7622418403625488\n",
      "  Advantage Mean       : 1.3441475488207288e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 35%|███▌      | 7/20 [01:50<03:26, 15.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7\n",
      "  KL Divergence        : 0.06807583570480347\n",
      "  Mean Return (Reward) : 1.9386159181594849\n",
      "  Advantage Mean       : 1.4979230300582458e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|████      | 8/20 [02:11<03:27, 17.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8\n",
      "  KL Divergence        : -0.017751026898622513\n",
      "  Mean Return (Reward) : 1.7773973941802979\n",
      "  Advantage Mean       : -9.885421548005979e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 45%|████▌     | 9/20 [02:23<02:54, 15.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9\n",
      "  KL Divergence        : 0.014478536322712898\n",
      "  Mean Return (Reward) : 2.193423271179199\n",
      "  Advantage Mean       : 2.2219193596129116e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|█████     | 10/20 [02:37<02:30, 15.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10\n",
      "  KL Divergence        : 0.09853384643793106\n",
      "  Mean Return (Reward) : 2.0787463188171387\n",
      "  Advantage Mean       : -3.928504810346567e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 55%|█████▌    | 11/20 [02:54<02:20, 15.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 11\n",
      "  KL Divergence        : 0.013210995122790337\n",
      "  Mean Return (Reward) : 1.5905194282531738\n",
      "  Advantage Mean       : -7.398745793807393e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|██████    | 12/20 [03:10<02:05, 15.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 12\n",
      "  KL Divergence        : 0.006261666305363178\n",
      "  Mean Return (Reward) : 1.8805618286132812\n",
      "  Advantage Mean       : -1.840064101088501e-09\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 65%|██████▌   | 13/20 [03:24<01:46, 15.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13\n",
      "  KL Divergence        : 0.07909096777439117\n",
      "  Mean Return (Reward) : 2.044520378112793\n",
      "  Advantage Mean       : 7.216770114837345e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 70%|███████   | 14/20 [03:40<01:33, 15.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 14\n",
      "  KL Divergence        : -0.00795726664364338\n",
      "  Mean Return (Reward) : 2.097381114959717\n",
      "  Advantage Mean       : 2.0897063635061386e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 75%|███████▌  | 15/20 [03:57<01:20, 16.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 15\n",
      "  KL Divergence        : 0.004027850925922394\n",
      "  Mean Return (Reward) : 1.366847276687622\n",
      "  Advantage Mean       : 1.0920253146196046e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|████████  | 16/20 [04:09<00:59, 14.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16\n",
      "  KL Divergence        : 0.038326188921928406\n",
      "  Mean Return (Reward) : 2.1520214080810547\n",
      "  Advantage Mean       : 8.325066858105856e-09\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 85%|████████▌ | 17/20 [04:25<00:45, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 17\n",
      "  KL Divergence        : 0.15688563883304596\n",
      "  Mean Return (Reward) : 1.8849300146102905\n",
      "  Advantage Mean       : 6.520036066604007e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 90%|█████████ | 18/20 [04:39<00:29, 14.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 18\n",
      "  KL Divergence        : 0.18081429600715637\n",
      "  Mean Return (Reward) : 1.954123616218567\n",
      "  Advantage Mean       : -3.4959867889483576e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 95%|█████████▌| 19/20 [04:56<00:15, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19\n",
      "  KL Divergence        : 0.19736091792583466\n",
      "  Mean Return (Reward) : 2.006293773651123\n",
      "  Advantage Mean       : 1.207381075118974e-07\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [05:09<00:00, 15.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20\n",
      "  KL Divergence        : 0.05986378714442253\n",
      "  Mean Return (Reward) : 2.3082714080810547\n",
      "  Advantage Mean       : -3.8824705228535095e-08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "from trl.core import LengthSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "sentiment_pipe = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=reward_model_raw,\n",
    "    device=device,\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "reward_logits_kwargs = {\n",
    "    \"top_k\": None,\n",
    "    \"function_to_apply\": \"none\",  \n",
    "    \"batch_size\": 16\n",
    "}\n",
    "reward_probabilities_kwargs = {\n",
    "    \"top_k\": None,\n",
    "    \"function_to_apply\": \"softmax\",  \n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "print(\"Reward model output:\")\n",
    "print(\"For non-toxic text:\")\n",
    "print(sentiment_pipe(non_toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(non_toxic_text, **reward_probabilities_kwargs))\n",
    "\n",
    "print(\"For toxic text:\")\n",
    "print(sentiment_pipe(toxic_text, **reward_logits_kwargs))\n",
    "print(sentiment_pipe(toxic_text, **reward_probabilities_kwargs))\n",
    "\n",
    "output_min_length = 100\n",
    "output_max_length = 400\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "max_ppo_steps = 20\n",
    "not_hate_index = 0  \n",
    "\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader), total=max_ppo_steps):\n",
    "    if step >= max_ppo_steps:\n",
    "        break\n",
    "\n",
    "    prompt_tensors = batch[\"input_ids\"]\n",
    "    summary_tensors = []\n",
    "\n",
    "    for prompt_tensor in prompt_tensors:\n",
    "        max_new_tokens = output_length_sampler()\n",
    "        generation_kwargs[\"max_new_tokens\"] = max_new_tokens\n",
    "\n",
    "        output = ppo_trainer.generate(prompt_tensor, **generation_kwargs)\n",
    "        summary_tensors.append(output.squeeze()[-max_new_tokens:])\n",
    "\n",
    "    batch[\"response\"] = [tokenizer.decode(r, skip_special_tokens=True) for r in summary_tensors]\n",
    "\n",
    "    query_response_pairs = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    rewards = sentiment_pipe(query_response_pairs, **reward_logits_kwargs)\n",
    "    reward_tensors = [torch.tensor(r[not_hate_index][\"score\"]) for r in rewards]\n",
    "\n",
    "    stats = ppo_trainer.step(prompt_tensors, summary_tensors, reward_tensors)\n",
    "    ppo_trainer.log_stats(stats, batch, reward_tensors)\n",
    "\n",
    "    print(f\"Step {step + 1}\")\n",
    "    print(f\"  KL Divergence        : {stats['objective/kl']}\")\n",
    "    print(f\"  Mean Return (Reward) : {stats['ppo/returns/mean']}\")\n",
    "    print(f\"  Advantage Mean       : {stats['ppo/policy/advantages_mean']}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/ppo_tuned_model_FLAN/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/ppo_tuned_model_FLAN/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/ppo_tuned_model_FLAN/spiece.model',\n",
       " '/content/drive/MyDrive/ppo_tuned_model_FLAN/added_tokens.json',\n",
       " '/content/drive/MyDrive/ppo_tuned_model_FLAN/tokenizer.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/ppo_tuned_model_FLAN\"\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "ppo_trainer.model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:40<00:00,  1.64s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                      query  \\\n",
      "0   Summarize the following conversation. #Person1#: Hello, Jane. #Person2#: Hi, Harry. Did you have a good summer holiday? #Person1#: Sure. I went for my holiday on my uncle's farm. #Person2#: Really...   \n",
      "1   Summarize the following conversation. #Person1#: Hello, Jill. #Person2#: Tom, You're back, come in please. How are you? #Person1#: Fine, only a little tired. #Person2#: You'll recover after a good...   \n",
      "2   Summarize the following conversation. #Person1#: Hello? Is that Mark? #Person2#: How are you? I haven't heard from you in ages. #Person1#: I've been overseas, So have you been busy lately? #Person...   \n",
      "3   Summarize the following conversation. #Person1#: Hi Paul. How are you, friend. #Person2#: Not good. My cousin is driving me up the wall. #Person1#: How so? #Person2#: He stays up untill all hours ...   \n",
      "4   Summarize the following conversation. #Person1#: Ladies and gentlemen, welcome to tonight's fashion show. #Person2#: We see you are all dressed to the nines. #Person1#: How very appropriate, becau...   \n",
      "5   Summarize the following conversation. #Person1#: Help me organize these coins. #Person2#: That's a lot of money! What did you do? Break the piggy bank? #Person1#: Yeah, I'm gonna go to the bank an...   \n",
      "6   Summarize the following conversation. #Person1#: Hello, this is the 911 emergency operator. #Person2#: Help! Help! Please, help me! #Person1#: Sir, please calm down and explain exactly what is hap...   \n",
      "7   Summarize the following conversation. #Person1#: Hey, Wen! Welcome to D. C.! Glad you came out to visit! #Person2#: Thanks for inviting me. Actually, I've never been anywhere with so many black pe...   \n",
      "8   Summarize the following conversation. #Person1#: Congratulations, Vivian. You won the grand prize, again. #Person2#: Isn't it just great! I just knew I'd win! #Person1#: You did? How? Did you wear...   \n",
      "9   Summarize the following conversation. #Person1#: Here we are, Ryan! This is where we're going to celebrate! #Person2#: It's a ETV palace! I'm glad I brought my platinum card. #Person1#: You won't ...   \n",
      "10  Summarize the following conversation. #Person1#: Mum, I am so excited that I don't want to go to bed. #Person2#: John, I know you will go out on a picnic with your classmates. But you should try t...   \n",
      "11  Summarize the following conversation. #Person1#: The train is leaving. Hurry up! Which car are we in? #Person2#: Let me see. Oh, No. 11. #Person1#: Here we are, Car 11. Let's get in. #Person2#: Se...   \n",
      "12  Summarize the following conversation. #Person1#: Hello, May I speak to Mary, please? #Person2#: Speaking, Who's calling please? #Person1#: Hi Mary, This is Tom. #Person2#: Oh, Hi Tom, how have you...   \n",
      "13  Summarize the following conversation. #Person1#: Do you know Yahoo Greetings, Edgar? #Person2#: Sure. It's a popular e-card website. #Person1#: Can you tell me how to send one on it? #Person2#: Ok...   \n",
      "14  Summarize the following conversation. #Person1#: Did your company go union? I heard that many companies in out industry are being unionized, so It's getting harder and harder to compete on a level...   \n",
      "15  Summarize the following conversation. #Person1#: What can I do for you, sir? #Person2#: I'm looking for a jacket for my son. #Person1#: Come with me, please. Here are jackets for boys. #Person2#: ...   \n",
      "16  Summarize the following conversation. #Person1#: Well, I certainly have enjoyed my stay in Edinburgh, Peter. Thanks for all your help and thanks to Gene as well for showing me around. #Person2#: W...   \n",
      "17  Summarize the following conversation. #Person1#: Here. Keep the change. #Person2#: Oh, thank you very much. #Person1#: You're welcome. By the way, is there a pay phone near here? #Person2#: Yes, t...   \n",
      "18  Summarize the following conversation. #Person1#: Hello! So you are leaving today. #Person2#: Hello. Thank you for seeing me off. You actually don't need to bother. #Person1#: It is my pleasure to ...   \n",
      "19  Summarize the following conversation. #Person1#: Honey, since you are American, which hand should I use to hold the fork? #Person2#: Left for the fork and right for the knife. #Person1#: Got it. I...   \n",
      "20  Summarize the following conversation. #Person1#: What do you like to do in your spare time? #Person2#: I like playing chess. #Person1#: Do you have any hobbies besides playing chess? #Person2#: I'...   \n",
      "21  Summarize the following conversation. #Person1#: There will be a party at my new house this Saturday. Would you like to come? #Person2#: That sounds good, but I have French class in the morning an...   \n",
      "22  Summarize the following conversation. #Person1#: I'd like to go to Suzhou next week. Do you know how to get there by train? #Person2#: First, you should check the schedule and see which trains go ...   \n",
      "23  Summarize the following conversation. #Person1#: You only have an hour for lunch? #Person2#: No, now I only have 45 minutes. #Person1#: That's not enough. Where are we going? #Person2#: We can go ...   \n",
      "24  Summarize the following conversation. #Person1#: May I help you? #Person2#: Yes, I would like to buy a swimming suit for my older sister as a birthday present. #Person1#: What size does she wear? ...   \n",
      "\n",
      "                                                                                                                                                                                            response_before  \\\n",
      "0                                                                                                                     Person1: Hi, Harry. Note that the last person is Jane Hyde when she is off from work.   \n",
      "1                                                                                                                     The house was tidy, and the flowers had a good growing season. Thanks for helping me.   \n",
      "2                                                                                      When he arrives back at the office with the beer and rods, he would be happy to go fishing with Mark on the weekend.   \n",
      "3                                                        The feeling is it's not good for you, but a neighbour spoke to Sother. There wasn't a fault on his part. He gets severely overtime in the morning.   \n",
      "4                     Thank you so much for your patience and be ready to show your friends these great shoes! Could you please show off your new designer perfume and be ready for tonight's fashion show?   \n",
      "5                                                                                                 The goal, which will be to organize the coins, is to sort any money from the piggy bank into small piles.   \n",
      "6                                                                                                                                                                  #Person1: Hello, 911 emergency operator.   \n",
      "7                                                                                                                                 People at the community center are white black people who fill the store.   \n",
      "8                                                                                                                                                                       If it's the truth, scream with joy.   \n",
      "9   One of Ryan's younger friends and family wants to celebrate honeymoon to parents who live close to it. They're going to hold their wedding in the ETV, which is new. The parents want to hold it in ...   \n",
      "10                                                                                                                                                                      Tim and Madereck enjoy this picnic.   \n",
      "11                                                                                                                                                  The train is leaving and seat no. 11 is currently open.   \n",
      "12                                                                                                                                                                                         Talk now to Tom.   \n",
      "13                                                                                    #Person1#: Hi. Now, what? #Person2#: Send my friend a card on Yahoo Greetings, intereacted with First Family Readies.   \n",
      "14                                                                                                               Generally people are happy about it but to the employees why is it better for the workers?   \n",
      "15                                                                                                                                                            The jacket everyone wants has the same price.   \n",
      "16                                                                                                                                                      Time for hands-on activities, this is a party game.   \n",
      "17                                                                                                                                                          #Person1#: Sorry, I didn't see any change here.   \n",
      "18                                                                                                                                                           #Person1#: Hello. I saw you off earlier today.   \n",
      "19                                                                                                                                                                   Introduce yourself, and a sip of wine.   \n",
      "20                                                                                                                                      Person1: If you like basketball, you're more of a hopscotch person.   \n",
      "21                                                                                                                                      The party is at Person1's house on Saturday with cake and attitude.   \n",
      "22                                                                                                                                                                      Get in touch with a trusted friend.   \n",
      "23                                                            Person1 has to travel 45 minutes for lunch. She will have extra time chances for scarfing down dinner. Also she will have sushi after school.   \n",
      "24                             #Person1# wants to buy a swimming suit for her younger sister for their birthday. #Person2# wants to buy a bright one. #Person1# has a budget department on the first floor.   \n",
      "\n",
      "    reward_before  \\\n",
      "0        2.459215   \n",
      "1        4.096716   \n",
      "2        3.896032   \n",
      "3        2.966087   \n",
      "4        4.086845   \n",
      "5        3.194796   \n",
      "6        3.024493   \n",
      "7        0.279679   \n",
      "8        2.619161   \n",
      "9        2.921001   \n",
      "10       3.503016   \n",
      "11       4.065499   \n",
      "12       1.994610   \n",
      "13       2.808177   \n",
      "14       2.229844   \n",
      "15       3.472419   \n",
      "16       3.724649   \n",
      "17       3.701590   \n",
      "18       3.731444   \n",
      "19       2.420433   \n",
      "20       1.903953   \n",
      "21       2.791882   \n",
      "22       3.762805   \n",
      "23       1.386092   \n",
      "24       3.433033   \n",
      "\n",
      "                                                                                                                                                                                             response_after  \\\n",
      "0                    Jane went to her uncle's farm three times, driving the tractor, taking care of the fruit garden, and teaching everyone. She also taught herself how to drive a lawn mower on the farm.   \n",
      "1                                                                                                                       From floor to ceiling, I can hear Jill and the neighbors whistling as Tom rolls in.   \n",
      "2   Everyone is complaining about the bill because someone else broke up with them this week. The bill was waiting for them so they could try to get together for some beer and water. Arky is going fis...   \n",
      "3                                                                                                                                                                                           Not good, Paul.   \n",
      "4                         #Parliament1: We are proud to welcome you to our Fashion Show. #Parliament2: We are making an invitation to all of our guests at our dressing rooms, Bellingham Hotel and Casino.   \n",
      "5                                                                                                                                      Person1 will sort money into 6 piles with coins, quarters and dimes.   \n",
      "6                                                                                                                                                          Stay calm and explain exactly what is happening.   \n",
      "7                                                       Black people are extra welcome to the Mexican organization, CC. The group invites black sports fans to attend a disco party in the university club.   \n",
      "8                                                                                                                                                                              #Person2: Thank you, Vivian.   \n",
      "9   The entire family showed up on Time Night Thursday evening and were really excited for Ron and Ryan's bachelor's party tonight. They think Stanley is a really good singer. They'll move towards the...   \n",
      "10                                                                                                                                                                 Primary class today is going to be busy.   \n",
      "11                                                                                                                                                                                     Hamilton is waiting.   \n",
      "12                                                                                                                                                                   Tom will pick up Person1 at 6 o'clock.   \n",
      "13                                                                                                                                                  #Person1: I am asked what e-card website are you using.   \n",
      "14                                                                                                                                         The next time you're talking about unions, think about it again.   \n",
      "15                                                                                                                                                                                    You are welcome, sir.   \n",
      "16                                                                                                                                                              I'm very pleased with my stay in Edinburgh.   \n",
      "17                                                                                                                                       #Person1#: Sorry to say we're running short. Are you ready to pay?   \n",
      "18                                                                                                    Officials at Uber and its sister company are meeting to cue the two about the status of the incident.   \n",
      "19                                                                                                 #Person1#: Of course, Dinner is a bit expensive but once you get there, you still need to come prepared.   \n",
      "20                                                                                                                    #Person1#: I am a friend of Person2 so I need to know something about you and for me.   \n",
      "21                The party starts in evening at Person1's New House this Saturday. People are asking about some things to bring to the party that include apples, bananas, applesauce, and powdered sugar.   \n",
      "22                                                                          Check in with the train schedule and get a ticket. Catch a connecting train at the station, then travel down the West Turnpike.   \n",
      "23                                                                                                                                 The meeting starts at 12:00 today and before the clock strikes 12:30 pm.   \n",
      "24                                                                                                                                                                         #Person1#: Thanks for your help.   \n",
      "\n",
      "    reward_after  \n",
      "0       3.215431  \n",
      "1       3.873422  \n",
      "2       2.661874  \n",
      "3       2.869358  \n",
      "4       3.922457  \n",
      "5       2.906338  \n",
      "6       3.267280  \n",
      "7       0.579977  \n",
      "8       2.248540  \n",
      "9       3.626835  \n",
      "10      3.734478  \n",
      "11      3.863837  \n",
      "12      1.742499  \n",
      "13      3.116134  \n",
      "14      2.074817  \n",
      "15      3.438254  \n",
      "16      4.097268  \n",
      "17      3.755370  \n",
      "18      4.277030  \n",
      "19      1.989592  \n",
      "20      2.565062  \n",
      "21      3.583677  \n",
      "22      3.814396  \n",
      "23      3.388463  \n",
      "24      3.320551  \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ref_model.to(device)\n",
    "ppo_model.to(device)\n",
    "\n",
    "batch_size = 25\n",
    "compare_results = {}\n",
    "\n",
    "df_batch = dataset[\"test\"][0:batch_size]\n",
    "compare_results[\"query\"] = df_batch[\"query\"]\n",
    "prompt_tensors = df_batch[\"input_ids\"]\n",
    "\n",
    "summary_tensors_ref = []\n",
    "summary_tensors = []\n",
    "\n",
    "output_min_length = 100\n",
    "output_max_length = 400\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"min_length\": 5,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True\n",
    "}\n",
    "\n",
    "for i in tqdm(range(batch_size)):\n",
    "    gen_len = output_length_sampler()\n",
    "    generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "\n",
    "    input_tensor = torch.as_tensor(prompt_tensors[i]).unsqueeze(dim=0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ref_output = ref_model.generate(input_ids=input_tensor, **generation_kwargs)\n",
    "        summary_tensors_ref.append(ref_output.squeeze()[-gen_len:])\n",
    "\n",
    "        ppo_output = ppo_model.generate(input_ids=input_tensor, **generation_kwargs)\n",
    "        summary_tensors.append(ppo_output.squeeze()[-gen_len:])\n",
    "\n",
    "compare_results[\"response_before\"] = [tokenizer.decode(tensor, skip_special_tokens=True) for tensor in summary_tensors_ref]\n",
    "compare_results[\"response_after\"] = [tokenizer.decode(tensor, skip_special_tokens=True) for tensor in summary_tensors]\n",
    "\n",
    "texts_before = [q + \" \" + r for q, r in zip(compare_results[\"query\"], compare_results[\"response_before\"])]\n",
    "texts_after = [q + \" \" + r for q, r in zip(compare_results[\"query\"], compare_results[\"response_after\"])]\n",
    "\n",
    "reward_kwargs = {\n",
    "    \"top_k\": None,\n",
    "    \"function_to_apply\": \"none\",\n",
    "    \"batch_size\": 16\n",
    "}\n",
    "\n",
    "rewards_before = sentiment_pipe(texts_before, **reward_kwargs)\n",
    "rewards_after = sentiment_pipe(texts_after, **reward_kwargs)\n",
    "\n",
    "not_hate_index = 0  \n",
    "\n",
    "compare_results[\"reward_before\"] = [reward[not_hate_index][\"score\"] for reward in rewards_before]\n",
    "compare_results[\"reward_after\"] = [reward[not_hate_index][\"score\"] for reward in rewards_after]\n",
    "\n",
    "import pandas as pd\n",
    "df_compare = pd.DataFrame(compare_results)\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "print(df_compare[[\"query\", \"response_before\", \"reward_before\", \"response_after\", \"reward_after\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"]]\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"Summarize the following conversation. #Person1#: Hey, Wen! Welcome to D. C.! Glad you came out to visit! #Person2#: Thanks for inviting me. Actually, I've never been anywhere with so many black people before. It's different. #Person1#: Howard is eighty percent black. But there are whites, and even Asians here. Thankfully, it's also coed. #Person2#: Great! Is your, too? #Person1#: Sorry, nope. But the Alpha Phi Alpha's are throwing a party tonight. #Person2#: That's a black fraternity, right? So we should see some dancing! Summary: </s>\",\n          \"Summarize the following conversation. #Person1#: Did your company go union? I heard that many companies in out industry are being unionized, so It's getting harder and harder to compete on a level playing field. #Person2#: Yes, we're hopping on the bandwagon and signing up for the union. Mostly people are pretty happy about it... I guess it depends on if you are in management or in the labor force. #Person1#: Management isn't looking on the labor unions too favorably, I'd guess. I don't blame them... labor unions can really put the squeeze on the executives. #Person2#: Sure... but it's probably better for the workers, because the union's whole purpose is to look out for the little guys. The only way that the little guys can take on the big bosses is if they unite. Labor unions are all about getting a voice for the underdog. Summary: </s>\",\n          \"Summarize the following conversation. #Person1#: You only have an hour for lunch? #Person2#: No, now I only have 45 minutes. #Person1#: That's not enough. Where are we going? #Person2#: We can go to a place near the mall. #Person1#: Oh, alright, let's go across the street. We can eat at Tony's Italian restaurant. I love their pizza. #Person2#: I love their food, too. But they are really slow. Last week I waited 30 minutes for my food. #Person1#: OK. Let's have sushi at Dave's. We can be in and out in 20 minutes. #Person2#: Today is Thursday, Dave's isn't open. #Person1#: Oh, right. Then, let's go to the Jungle Cafe. We can be there in 60 seconds. #Person2#: Great idea. Summary: </s>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_before\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"People at the community center are white black people who fill the store.\",\n          \"Generally people are happy about it but to the employees why is it better for the workers?\",\n          \"Person1 has to travel 45 minutes for lunch. She will have extra time chances for scarfing down dinner. Also she will have sushi after school.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reward_before\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9313651089850808,\n        \"min\": 0.27967891097068787,\n        \"max\": 4.096715927124023,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.27967891097068787,\n          2.229844093322754,\n          1.3860915899276733\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_after\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"Black people are extra welcome to the Mexican organization, CC. The group invites black sports fans to attend a disco party in the university club.\",\n          \"The next time you're talking about unions, think about it again.\",\n          \"The meeting starts at 12:00 today and before the clock strikes 12:30 pm.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reward_after\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8694683918187478,\n        \"min\": 0.5799767374992371,\n        \"max\": 4.277029991149902,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.5799767374992371,\n          2.0748167037963867,\n          3.388463258743286\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reward_diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5972890583562733,\n        \"min\": -1.2341582775115967,\n        \"max\": 2.002371668815613,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.3002978265285492,\n          -0.1550273895263672,\n          2.002371668815613\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-8daf916b-4ab5-4272-8048-24a57afec8df\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response_before</th>\n",
       "      <th>reward_before</th>\n",
       "      <th>response_after</th>\n",
       "      <th>reward_after</th>\n",
       "      <th>reward_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize the following conversation. #Person1#: You only have an hour for lunch? #Person2#: No, now I only have 45 minutes. #Person1#: That's not enough. Where are we going? #Person2#: We can go to a place near the mall. #Person1#: Oh, alright, let's go across the street. We can eat at Tony's Italian restaurant. I love their pizza. #Person2#: I love their food, too. But they are really slow. Last week I waited 30 minutes for my food. #Person1#: OK. Let's have sushi at Dave's. We can be in a...</td>\n",
       "      <td>Person1 has to travel 45 minutes for lunch. She will have extra time chances for scarfing down dinner. Also she will have sushi after school.</td>\n",
       "      <td>1.386092</td>\n",
       "      <td>The meeting starts at 12:00 today and before the clock strikes 12:30 pm.</td>\n",
       "      <td>3.388463</td>\n",
       "      <td>2.002372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summarize the following conversation. #Person1#: There will be a party at my new house this Saturday. Would you like to come? #Person2#: That sounds good, but I have French class in the morning and dance class in the afternoon. #Person1#: That's OK. The party is to start in the evening, and you can come after the dance class. #Person2#: Great! Should I bring something? #Person1#: Yes, it's a potluck party, so you should prepare something to eat. #Person2#: No problem. A roast turkey, salad, ...</td>\n",
       "      <td>The party is at Person1's house on Saturday with cake and attitude.</td>\n",
       "      <td>2.791882</td>\n",
       "      <td>The party starts in evening at Person1's New House this Saturday. People are asking about some things to bring to the party that include apples, bananas, applesauce, and powdered sugar.</td>\n",
       "      <td>3.583677</td>\n",
       "      <td>0.791795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello, Jane. #Person2#: Hi, Harry. Did you have a good summer holiday? #Person1#: Sure. I went for my holiday on my uncle's farm. #Person2#: Really? What interesting things did you do there? #Person1#: I helped get in some rice, take care of the fruit garden and drive the tractor. #Person2#: Drive a tractor? #Person1#: Yes. It was easy to learn. Did you go away for your holiday, Jane? #Person2#: Oh, no. I just stayed at home. My mother has bee...</td>\n",
       "      <td>Person1: Hi, Harry. Note that the last person is Jane Hyde when she is off from work.</td>\n",
       "      <td>2.459215</td>\n",
       "      <td>Jane went to her uncle's farm three times, driving the tractor, taking care of the fruit garden, and teaching everyone. She also taught herself how to drive a lawn mower on the farm.</td>\n",
       "      <td>3.215431</td>\n",
       "      <td>0.756216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Here we are, Ryan! This is where we're going to celebrate! #Person2#: It's a ETV palace! I'm glad I brought my platinum card. #Person1#: You won't need it. Stanley, my best man, is going to treat everybody! #Person2#: Where is Stanley? It was his idea to have the bachelor's party at a ETV, wasn't it? #Person1#: If it were up to Stanley, we'd have the wedding in the ETV! He loves to sing. #Person2#: Then I bet he's really good! #Person1#: Well,...</td>\n",
       "      <td>One of Ryan's younger friends and family wants to celebrate honeymoon to parents who live close to it. They're going to hold their wedding in the ETV, which is new. The parents want to hold it in the same spot as People.</td>\n",
       "      <td>2.921001</td>\n",
       "      <td>The entire family showed up on Time Night Thursday evening and were really excited for Ron and Ryan's bachelor's party tonight. They think Stanley is a really good singer. They'll move towards the ETV.</td>\n",
       "      <td>3.626835</td>\n",
       "      <td>0.705834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summarize the following conversation. #Person1#: What do you like to do in your spare time? #Person2#: I like playing chess. #Person1#: Do you have any hobbies besides playing chess? #Person2#: I'm afraid not. #Person1#: Do you have any hobbies like playing tennis or things like that? #Person2#: Oh, yes. I like playing basketball. #Person1#: Can you tell me why you like it? #Person2#: Because I like the feeling of cooperating with others. Summary: &lt;/s&gt;</td>\n",
       "      <td>Person1: If you like basketball, you're more of a hopscotch person.</td>\n",
       "      <td>1.903953</td>\n",
       "      <td>#Person1#: I am a friend of Person2 so I need to know something about you and for me.</td>\n",
       "      <td>2.565062</td>\n",
       "      <td>0.661109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello! So you are leaving today. #Person2#: Hello. Thank you for seeing me off. You actually don't need to bother. #Person1#: It is my pleasure to see you off. #Person2#: Thanks a lot. I hope to see you again. #Person1#: I hope so, too. #Person2#: Thanks again for everything you have done for me. #Person1#: You're welcome. Have a nice trip! Summary: &lt;/s&gt;</td>\n",
       "      <td>#Person1#: Hello. I saw you off earlier today.</td>\n",
       "      <td>3.731444</td>\n",
       "      <td>Officials at Uber and its sister company are meeting to cue the two about the status of the incident.</td>\n",
       "      <td>4.277030</td>\n",
       "      <td>0.545586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Well, I certainly have enjoyed my stay in Edinburgh, Peter. Thanks for all your help and thanks to Gene as well for showing me around. #Person2#: Well, we both enjoyed it, too. How long will you stay in York before you go back? #Person1#: 2 days. Look, when are you going to be in London again? You must bring Gene with you and we can all get together again. #Person2#: Yes, I'll do that. That's your train, isn't it? #Person1#: Yes, I'd better go...</td>\n",
       "      <td>Time for hands-on activities, this is a party game.</td>\n",
       "      <td>3.724649</td>\n",
       "      <td>I'm very pleased with my stay in Edinburgh.</td>\n",
       "      <td>4.097268</td>\n",
       "      <td>0.372619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Do you know Yahoo Greetings, Edgar? #Person2#: Sure. It's a popular e-card website. #Person1#: Can you tell me how to send one on it? #Person2#: Okay. Did you get the Yahoo ID? #Person1#: ID? What's that? #Person2#: I mean, you must register first before you send a card. #Person1#: Oh. I see. But I have done it. #Person2#: Ok. Choose the card which you like best, and fill in the following blanks with both your and your friend's names and e-mai...</td>\n",
       "      <td>#Person1#: Hi. Now, what? #Person2#: Send my friend a card on Yahoo Greetings, intereacted with First Family Readies.</td>\n",
       "      <td>2.808177</td>\n",
       "      <td>#Person1: I am asked what e-card website are you using.</td>\n",
       "      <td>3.116134</td>\n",
       "      <td>0.307957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hey, Wen! Welcome to D. C.! Glad you came out to visit! #Person2#: Thanks for inviting me. Actually, I've never been anywhere with so many black people before. It's different. #Person1#: Howard is eighty percent black. But there are whites, and even Asians here. Thankfully, it's also coed. #Person2#: Great! Is your, too? #Person1#: Sorry, nope. But the Alpha Phi Alpha's are throwing a party tonight. #Person2#: That's a black fraternity, right?...</td>\n",
       "      <td>People at the community center are white black people who fill the store.</td>\n",
       "      <td>0.279679</td>\n",
       "      <td>Black people are extra welcome to the Mexican organization, CC. The group invites black sports fans to attend a disco party in the university club.</td>\n",
       "      <td>0.579977</td>\n",
       "      <td>0.300298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello, this is the 911 emergency operator. #Person2#: Help! Help! Please, help me! #Person1#: Sir, please calm down and explain exactly what is happening. #Person2#: Calm down? My car broke down on the freeway! I have a woman passenger and she's about to have a baby! #Person1#: Relax, sir, and explain exactly where you are. #Person2#: I'm in the southward lane of the Lincoln freeway, about 15 miles from the Washington tunnel. #Person1#: Okay. ...</td>\n",
       "      <td>#Person1: Hello, 911 emergency operator.</td>\n",
       "      <td>3.024493</td>\n",
       "      <td>Stay calm and explain exactly what is happening.</td>\n",
       "      <td>3.267280</td>\n",
       "      <td>0.242787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Mum, I am so excited that I don't want to go to bed. #Person2#: John, I know you will go out on a picnic with your classmates. But you should try to fall asleep; otherwise you will not get up on time tomorrow morning. Summary: &lt;/s&gt;</td>\n",
       "      <td>Tim and Madereck enjoy this picnic.</td>\n",
       "      <td>3.503016</td>\n",
       "      <td>Primary class today is going to be busy.</td>\n",
       "      <td>3.734478</td>\n",
       "      <td>0.231462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Here. Keep the change. #Person2#: Oh, thank you very much. #Person1#: You're welcome. By the way, is there a pay phone near here? #Person2#: Yes, there's one just on the other side of this building. Do you have any small change? #Person1#: Yes, I do. Thank you. Summary: &lt;/s&gt;</td>\n",
       "      <td>#Person1#: Sorry, I didn't see any change here.</td>\n",
       "      <td>3.701590</td>\n",
       "      <td>#Person1#: Sorry to say we're running short. Are you ready to pay?</td>\n",
       "      <td>3.755370</td>\n",
       "      <td>0.053780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Summarize the following conversation. #Person1#: I'd like to go to Suzhou next week. Do you know how to get there by train? #Person2#: First, you should check the schedule and see which trains go to Suzhou. Make sure which train you want to take and book a ticket. #Person1#: I see. Do you know how much the ticket is? #Person2#: It depends on which train do you take. #Person1#: Is it far from here to Suzhou? #Person2#: Yes, it stops more than ten times on the way to Suzhou. #Person1#: How lon...</td>\n",
       "      <td>Get in touch with a trusted friend.</td>\n",
       "      <td>3.762805</td>\n",
       "      <td>Check in with the train schedule and get a ticket. Catch a connecting train at the station, then travel down the West Turnpike.</td>\n",
       "      <td>3.814396</td>\n",
       "      <td>0.051591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Summarize the following conversation. #Person1#: What can I do for you, sir? #Person2#: I'm looking for a jacket for my son. #Person1#: Come with me, please. Here are jackets for boys. #Person2#: The black one is nice. How much is it? #Person1#: Twenty five pounds. #Person2#: Oh, I'm afraid it's too expensive. #Person1#: What about the blue one over there? It looks nice, too. And it's cheaper. #Person2#: But it's a bit small. Have you a bigger size? #Person1#: Sorry, we haven't. But we'll ge...</td>\n",
       "      <td>The jacket everyone wants has the same price.</td>\n",
       "      <td>3.472419</td>\n",
       "      <td>You are welcome, sir.</td>\n",
       "      <td>3.438254</td>\n",
       "      <td>-0.034165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hi Paul. How are you, friend. #Person2#: Not good. My cousin is driving me up the wall. #Person1#: How so? #Person2#: He stays up untill all hours of the night, and he never lifts a finger to help. #Person1#: Have you talk to him about it? #Person2#: Not yet, but I have to soon. He's eating me out of house and home. I caught him reading the fridge again last night #Person1#: Hahaha, Maybe that will help you lose weight. #Person2#: This is no l...</td>\n",
       "      <td>The feeling is it's not good for you, but a neighbour spoke to Sother. There wasn't a fault on his part. He gets severely overtime in the morning.</td>\n",
       "      <td>2.966087</td>\n",
       "      <td>Not good, Paul.</td>\n",
       "      <td>2.869358</td>\n",
       "      <td>-0.096729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Summarize the following conversation. #Person1#: May I help you? #Person2#: Yes, I would like to buy a swimming suit for my older sister as a birthday present. #Person1#: What size does she wear? #Person2#: Medium, the same size as I do. #Person1#: Would she like this style? #Person2#: No, do you have something different from this one? #Person1#: What about that one? #Person2#: The style is fine, but the color is too dark. Do you have something brighter? #Person1#: How about this one? It's t...</td>\n",
       "      <td>#Person1# wants to buy a swimming suit for her younger sister for their birthday. #Person2# wants to buy a bright one. #Person1# has a budget department on the first floor.</td>\n",
       "      <td>3.433033</td>\n",
       "      <td>#Person1#: Thanks for your help.</td>\n",
       "      <td>3.320551</td>\n",
       "      <td>-0.112482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Did your company go union? I heard that many companies in out industry are being unionized, so It's getting harder and harder to compete on a level playing field. #Person2#: Yes, we're hopping on the bandwagon and signing up for the union. Mostly people are pretty happy about it... I guess it depends on if you are in management or in the labor force. #Person1#: Management isn't looking on the labor unions too favorably, I'd guess. I don't blam...</td>\n",
       "      <td>Generally people are happy about it but to the employees why is it better for the workers?</td>\n",
       "      <td>2.229844</td>\n",
       "      <td>The next time you're talking about unions, think about it again.</td>\n",
       "      <td>2.074817</td>\n",
       "      <td>-0.155027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Ladies and gentlemen, welcome to tonight's fashion show. #Person2#: We see you are all dressed to the nines. #Person1#: How very appropriate, because tonight we have a most dazzling show for you! #Person2#: Yes, this runway is going to sparkle with glamour and style! #Person1#: Some of tonight's highlights are dressed in the latest straight from Shanghai. #Person2#: And others directly from New York. #Person1#: So, sit back and relax and get y...</td>\n",
       "      <td>Thank you so much for your patience and be ready to show your friends these great shoes! Could you please show off your new designer perfume and be ready for tonight's fashion show?</td>\n",
       "      <td>4.086845</td>\n",
       "      <td>#Parliament1: We are proud to welcome you to our Fashion Show. #Parliament2: We are making an invitation to all of our guests at our dressing rooms, Bellingham Hotel and Casino.</td>\n",
       "      <td>3.922457</td>\n",
       "      <td>-0.164387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Summarize the following conversation. #Person1#: The train is leaving. Hurry up! Which car are we in? #Person2#: Let me see. Oh, No. 11. #Person1#: Here we are, Car 11. Let's get in. #Person2#: Seats No. 20 and 21. It's nice that we have got a window seat. #Person1#: Let's put our suitcases on the rack. #Person2#: Oh, the baggage rack is full. Put them under the seat for the time being. #Person1#: All right. Summary: &lt;/s&gt;</td>\n",
       "      <td>The train is leaving and seat no. 11 is currently open.</td>\n",
       "      <td>4.065499</td>\n",
       "      <td>Hamilton is waiting.</td>\n",
       "      <td>3.863837</td>\n",
       "      <td>-0.201662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello, Jill. #Person2#: Tom, You're back, come in please. How are you? #Person1#: Fine, only a little tired. #Person2#: You'll recover after a good night's sleep. #Person1#: Thank you very much for looking after my house in my absence. #Person2#: That's all right. Would you have a cup of coffee? #Person1#: Yes, Please. It's very kind of you. #Person2#: Don't mention it. #Person1#: The rooms are very tidy and the flowers grew very well. You are...</td>\n",
       "      <td>The house was tidy, and the flowers had a good growing season. Thanks for helping me.</td>\n",
       "      <td>4.096716</td>\n",
       "      <td>From floor to ceiling, I can hear Jill and the neighbors whistling as Tom rolls in.</td>\n",
       "      <td>3.873422</td>\n",
       "      <td>-0.223294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello, May I speak to Mary, please? #Person2#: Speaking, Who's calling please? #Person1#: Hi Mary, This is Tom. #Person2#: Oh, Hi Tom, how have you been? #Person1#: Just fine. I see. Aren't you busying tomorrow evening? #Person2#: Let me see. Akha. No, I guess I'll be free. #Person1#: Well, why not dine out together and go to the moves. #Person2#: Sounds like a good idea. #Person1#: Ok. I'l l pick you up at 6 o'clock. #Person2#: Thank you for ...</td>\n",
       "      <td>Talk now to Tom.</td>\n",
       "      <td>1.994610</td>\n",
       "      <td>Tom will pick up Person1 at 6 o'clock.</td>\n",
       "      <td>1.742499</td>\n",
       "      <td>-0.252111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Help me organize these coins. #Person2#: That's a lot of money! What did you do? Break the piggy bank? #Person1#: Yeah, I'm gonna go to the bank and change it for bills, but first I have to separate them into little piles. #Person2#: Ok, I'll find all the quarters and dimes while you sort the nickels and pennies. #Person1#: Great, then we can add everything up and take it to the bank. #Person2#: I found some coins that are not from here. #Pers...</td>\n",
       "      <td>The goal, which will be to organize the coins, is to sort any money from the piggy bank into small piles.</td>\n",
       "      <td>3.194796</td>\n",
       "      <td>Person1 will sort money into 6 piles with coins, quarters and dimes.</td>\n",
       "      <td>2.906338</td>\n",
       "      <td>-0.288458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Congratulations, Vivian. You won the grand prize, again. #Person2#: Isn't it just great! I just knew I'd win! #Person1#: You did? How? Did you wear red underwear again this year? #Person2#: Not only that! #Person1#: Tell me! Tell me! What's your secret?! #Person2#: OK, OK. I'll whisper it to you, but you have to promise not to tell anyone! #Person1#: What?! You did that??!!! Summary: &lt;/s&gt;</td>\n",
       "      <td>If it's the truth, scream with joy.</td>\n",
       "      <td>2.619161</td>\n",
       "      <td>#Person2: Thank you, Vivian.</td>\n",
       "      <td>2.248540</td>\n",
       "      <td>-0.370621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Honey, since you are American, which hand should I use to hold the fork? #Person2#: Left for the fork and right for the knife. #Person1#: Got it. It's so troublesome to have western food. I've been learning the table manners, since we got married. But I still can't. #Person2#: Well, having western food is more about western culture. #Person1#: Which restaurant are we going to tonight? #Person2#: Sarah has booked a table at a newly opened weste...</td>\n",
       "      <td>Introduce yourself, and a sip of wine.</td>\n",
       "      <td>2.420433</td>\n",
       "      <td>#Person1#: Of course, Dinner is a bit expensive but once you get there, you still need to come prepared.</td>\n",
       "      <td>1.989592</td>\n",
       "      <td>-0.430840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Summarize the following conversation. #Person1#: Hello? Is that Mark? #Person2#: How are you? I haven't heard from you in ages. #Person1#: I've been overseas, So have you been busy lately? #Person2#: Pretty busy. So are you back for good? #Person1#: Yes, I was just wondering when you'd have time to go fishing. #Person2#: Well, I'm not working on the weekend, so we could grab some beer, ice and our fishing rods, and head out to the river. #Person1#: That sounds good. I've missed you my friend...</td>\n",
       "      <td>When he arrives back at the office with the beer and rods, he would be happy to go fishing with Mark on the weekend.</td>\n",
       "      <td>3.896032</td>\n",
       "      <td>Everyone is complaining about the bill because someone else broke up with them this week. The bill was waiting for them so they could try to get together for some beer and water. Arky is going fishing so they should bring the sandbags.</td>\n",
       "      <td>2.661874</td>\n",
       "      <td>-1.234158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8daf916b-4ab5-4272-8048-24a57afec8df')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-8daf916b-4ab5-4272-8048-24a57afec8df button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-8daf916b-4ab5-4272-8048-24a57afec8df');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-0ae0cb77-1dee-4c6b-8388-b3ac35b5df45\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ae0cb77-1dee-4c6b-8388-b3ac35b5df45')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-0ae0cb77-1dee-4c6b-8388-b3ac35b5df45 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  query  \\\n",
       "0   Summarize the following conversation. #Person1#: You only have an hour for lunch? #Person2#: No, now I only have 45 minutes. #Person1#: That's not enough. Where are we going? #Person2#: We can go to a place near the mall. #Person1#: Oh, alright, let's go across the street. We can eat at Tony's Italian restaurant. I love their pizza. #Person2#: I love their food, too. But they are really slow. Last week I waited 30 minutes for my food. #Person1#: OK. Let's have sushi at Dave's. We can be in a...   \n",
       "1   Summarize the following conversation. #Person1#: There will be a party at my new house this Saturday. Would you like to come? #Person2#: That sounds good, but I have French class in the morning and dance class in the afternoon. #Person1#: That's OK. The party is to start in the evening, and you can come after the dance class. #Person2#: Great! Should I bring something? #Person1#: Yes, it's a potluck party, so you should prepare something to eat. #Person2#: No problem. A roast turkey, salad, ...   \n",
       "2   Summarize the following conversation. #Person1#: Hello, Jane. #Person2#: Hi, Harry. Did you have a good summer holiday? #Person1#: Sure. I went for my holiday on my uncle's farm. #Person2#: Really? What interesting things did you do there? #Person1#: I helped get in some rice, take care of the fruit garden and drive the tractor. #Person2#: Drive a tractor? #Person1#: Yes. It was easy to learn. Did you go away for your holiday, Jane? #Person2#: Oh, no. I just stayed at home. My mother has bee...   \n",
       "3   Summarize the following conversation. #Person1#: Here we are, Ryan! This is where we're going to celebrate! #Person2#: It's a ETV palace! I'm glad I brought my platinum card. #Person1#: You won't need it. Stanley, my best man, is going to treat everybody! #Person2#: Where is Stanley? It was his idea to have the bachelor's party at a ETV, wasn't it? #Person1#: If it were up to Stanley, we'd have the wedding in the ETV! He loves to sing. #Person2#: Then I bet he's really good! #Person1#: Well,...   \n",
       "4                                              Summarize the following conversation. #Person1#: What do you like to do in your spare time? #Person2#: I like playing chess. #Person1#: Do you have any hobbies besides playing chess? #Person2#: I'm afraid not. #Person1#: Do you have any hobbies like playing tennis or things like that? #Person2#: Oh, yes. I like playing basketball. #Person1#: Can you tell me why you like it? #Person2#: Because I like the feeling of cooperating with others. Summary: </s>   \n",
       "5                                                                                                 Summarize the following conversation. #Person1#: Hello! So you are leaving today. #Person2#: Hello. Thank you for seeing me off. You actually don't need to bother. #Person1#: It is my pleasure to see you off. #Person2#: Thanks a lot. I hope to see you again. #Person1#: I hope so, too. #Person2#: Thanks again for everything you have done for me. #Person1#: You're welcome. Have a nice trip! Summary: </s>   \n",
       "6   Summarize the following conversation. #Person1#: Well, I certainly have enjoyed my stay in Edinburgh, Peter. Thanks for all your help and thanks to Gene as well for showing me around. #Person2#: Well, we both enjoyed it, too. How long will you stay in York before you go back? #Person1#: 2 days. Look, when are you going to be in London again? You must bring Gene with you and we can all get together again. #Person2#: Yes, I'll do that. That's your train, isn't it? #Person1#: Yes, I'd better go...   \n",
       "7   Summarize the following conversation. #Person1#: Do you know Yahoo Greetings, Edgar? #Person2#: Sure. It's a popular e-card website. #Person1#: Can you tell me how to send one on it? #Person2#: Okay. Did you get the Yahoo ID? #Person1#: ID? What's that? #Person2#: I mean, you must register first before you send a card. #Person1#: Oh. I see. But I have done it. #Person2#: Ok. Choose the card which you like best, and fill in the following blanks with both your and your friend's names and e-mai...   \n",
       "8   Summarize the following conversation. #Person1#: Hey, Wen! Welcome to D. C.! Glad you came out to visit! #Person2#: Thanks for inviting me. Actually, I've never been anywhere with so many black people before. It's different. #Person1#: Howard is eighty percent black. But there are whites, and even Asians here. Thankfully, it's also coed. #Person2#: Great! Is your, too? #Person1#: Sorry, nope. But the Alpha Phi Alpha's are throwing a party tonight. #Person2#: That's a black fraternity, right?...   \n",
       "9   Summarize the following conversation. #Person1#: Hello, this is the 911 emergency operator. #Person2#: Help! Help! Please, help me! #Person1#: Sir, please calm down and explain exactly what is happening. #Person2#: Calm down? My car broke down on the freeway! I have a woman passenger and she's about to have a baby! #Person1#: Relax, sir, and explain exactly where you are. #Person2#: I'm in the southward lane of the Lincoln freeway, about 15 miles from the Washington tunnel. #Person1#: Okay. ...   \n",
       "10                                                                                                                                                                                                                             Summarize the following conversation. #Person1#: Mum, I am so excited that I don't want to go to bed. #Person2#: John, I know you will go out on a picnic with your classmates. But you should try to fall asleep; otherwise you will not get up on time tomorrow morning. Summary: </s>   \n",
       "11                                                                                                                                                                                 Summarize the following conversation. #Person1#: Here. Keep the change. #Person2#: Oh, thank you very much. #Person1#: You're welcome. By the way, is there a pay phone near here? #Person2#: Yes, there's one just on the other side of this building. Do you have any small change? #Person1#: Yes, I do. Thank you. Summary: </s>   \n",
       "12  Summarize the following conversation. #Person1#: I'd like to go to Suzhou next week. Do you know how to get there by train? #Person2#: First, you should check the schedule and see which trains go to Suzhou. Make sure which train you want to take and book a ticket. #Person1#: I see. Do you know how much the ticket is? #Person2#: It depends on which train do you take. #Person1#: Is it far from here to Suzhou? #Person2#: Yes, it stops more than ten times on the way to Suzhou. #Person1#: How lon...   \n",
       "13  Summarize the following conversation. #Person1#: What can I do for you, sir? #Person2#: I'm looking for a jacket for my son. #Person1#: Come with me, please. Here are jackets for boys. #Person2#: The black one is nice. How much is it? #Person1#: Twenty five pounds. #Person2#: Oh, I'm afraid it's too expensive. #Person1#: What about the blue one over there? It looks nice, too. And it's cheaper. #Person2#: But it's a bit small. Have you a bigger size? #Person1#: Sorry, we haven't. But we'll ge...   \n",
       "14  Summarize the following conversation. #Person1#: Hi Paul. How are you, friend. #Person2#: Not good. My cousin is driving me up the wall. #Person1#: How so? #Person2#: He stays up untill all hours of the night, and he never lifts a finger to help. #Person1#: Have you talk to him about it? #Person2#: Not yet, but I have to soon. He's eating me out of house and home. I caught him reading the fridge again last night #Person1#: Hahaha, Maybe that will help you lose weight. #Person2#: This is no l...   \n",
       "15  Summarize the following conversation. #Person1#: May I help you? #Person2#: Yes, I would like to buy a swimming suit for my older sister as a birthday present. #Person1#: What size does she wear? #Person2#: Medium, the same size as I do. #Person1#: Would she like this style? #Person2#: No, do you have something different from this one? #Person1#: What about that one? #Person2#: The style is fine, but the color is too dark. Do you have something brighter? #Person1#: How about this one? It's t...   \n",
       "16  Summarize the following conversation. #Person1#: Did your company go union? I heard that many companies in out industry are being unionized, so It's getting harder and harder to compete on a level playing field. #Person2#: Yes, we're hopping on the bandwagon and signing up for the union. Mostly people are pretty happy about it... I guess it depends on if you are in management or in the labor force. #Person1#: Management isn't looking on the labor unions too favorably, I'd guess. I don't blam...   \n",
       "17  Summarize the following conversation. #Person1#: Ladies and gentlemen, welcome to tonight's fashion show. #Person2#: We see you are all dressed to the nines. #Person1#: How very appropriate, because tonight we have a most dazzling show for you! #Person2#: Yes, this runway is going to sparkle with glamour and style! #Person1#: Some of tonight's highlights are dressed in the latest straight from Shanghai. #Person2#: And others directly from New York. #Person1#: So, sit back and relax and get y...   \n",
       "18                                                                            Summarize the following conversation. #Person1#: The train is leaving. Hurry up! Which car are we in? #Person2#: Let me see. Oh, No. 11. #Person1#: Here we are, Car 11. Let's get in. #Person2#: Seats No. 20 and 21. It's nice that we have got a window seat. #Person1#: Let's put our suitcases on the rack. #Person2#: Oh, the baggage rack is full. Put them under the seat for the time being. #Person1#: All right. Summary: </s>   \n",
       "19  Summarize the following conversation. #Person1#: Hello, Jill. #Person2#: Tom, You're back, come in please. How are you? #Person1#: Fine, only a little tired. #Person2#: You'll recover after a good night's sleep. #Person1#: Thank you very much for looking after my house in my absence. #Person2#: That's all right. Would you have a cup of coffee? #Person1#: Yes, Please. It's very kind of you. #Person2#: Don't mention it. #Person1#: The rooms are very tidy and the flowers grew very well. You are...   \n",
       "20  Summarize the following conversation. #Person1#: Hello, May I speak to Mary, please? #Person2#: Speaking, Who's calling please? #Person1#: Hi Mary, This is Tom. #Person2#: Oh, Hi Tom, how have you been? #Person1#: Just fine. I see. Aren't you busying tomorrow evening? #Person2#: Let me see. Akha. No, I guess I'll be free. #Person1#: Well, why not dine out together and go to the moves. #Person2#: Sounds like a good idea. #Person1#: Ok. I'l l pick you up at 6 o'clock. #Person2#: Thank you for ...   \n",
       "21  Summarize the following conversation. #Person1#: Help me organize these coins. #Person2#: That's a lot of money! What did you do? Break the piggy bank? #Person1#: Yeah, I'm gonna go to the bank and change it for bills, but first I have to separate them into little piles. #Person2#: Ok, I'll find all the quarters and dimes while you sort the nickels and pennies. #Person1#: Great, then we can add everything up and take it to the bank. #Person2#: I found some coins that are not from here. #Pers...   \n",
       "22                                                             Summarize the following conversation. #Person1#: Congratulations, Vivian. You won the grand prize, again. #Person2#: Isn't it just great! I just knew I'd win! #Person1#: You did? How? Did you wear red underwear again this year? #Person2#: Not only that! #Person1#: Tell me! Tell me! What's your secret?! #Person2#: OK, OK. I'll whisper it to you, but you have to promise not to tell anyone! #Person1#: What?! You did that??!!! Summary: </s>   \n",
       "23  Summarize the following conversation. #Person1#: Honey, since you are American, which hand should I use to hold the fork? #Person2#: Left for the fork and right for the knife. #Person1#: Got it. It's so troublesome to have western food. I've been learning the table manners, since we got married. But I still can't. #Person2#: Well, having western food is more about western culture. #Person1#: Which restaurant are we going to tonight? #Person2#: Sarah has booked a table at a newly opened weste...   \n",
       "24  Summarize the following conversation. #Person1#: Hello? Is that Mark? #Person2#: How are you? I haven't heard from you in ages. #Person1#: I've been overseas, So have you been busy lately? #Person2#: Pretty busy. So are you back for good? #Person1#: Yes, I was just wondering when you'd have time to go fishing. #Person2#: Well, I'm not working on the weekend, so we could grab some beer, ice and our fishing rods, and head out to the river. #Person1#: That sounds good. I've missed you my friend...   \n",
       "\n",
       "                                                                                                                                                                                                                 response_before  \\\n",
       "0                                                                                  Person1 has to travel 45 minutes for lunch. She will have extra time chances for scarfing down dinner. Also she will have sushi after school.   \n",
       "1                                                                                                                                                            The party is at Person1's house on Saturday with cake and attitude.   \n",
       "2                                                                                                                                          Person1: Hi, Harry. Note that the last person is Jane Hyde when she is off from work.   \n",
       "3   One of Ryan's younger friends and family wants to celebrate honeymoon to parents who live close to it. They're going to hold their wedding in the ETV, which is new. The parents want to hold it in the same spot as People.   \n",
       "4                                                                                                                                                            Person1: If you like basketball, you're more of a hopscotch person.   \n",
       "5                                                                                                                                                                                 #Person1#: Hello. I saw you off earlier today.   \n",
       "6                                                                                                                                                                            Time for hands-on activities, this is a party game.   \n",
       "7                                                                                                          #Person1#: Hi. Now, what? #Person2#: Send my friend a card on Yahoo Greetings, intereacted with First Family Readies.   \n",
       "8                                                                                                                                                      People at the community center are white black people who fill the store.   \n",
       "9                                                                                                                                                                                       #Person1: Hello, 911 emergency operator.   \n",
       "10                                                                                                                                                                                           Tim and Madereck enjoy this picnic.   \n",
       "11                                                                                                                                                                               #Person1#: Sorry, I didn't see any change here.   \n",
       "12                                                                                                                                                                                           Get in touch with a trusted friend.   \n",
       "13                                                                                                                                                                                 The jacket everyone wants has the same price.   \n",
       "14                                                                            The feeling is it's not good for you, but a neighbour spoke to Sother. There wasn't a fault on his part. He gets severely overtime in the morning.   \n",
       "15                                                  #Person1# wants to buy a swimming suit for her younger sister for their birthday. #Person2# wants to buy a bright one. #Person1# has a budget department on the first floor.   \n",
       "16                                                                                                                                    Generally people are happy about it but to the employees why is it better for the workers?   \n",
       "17                                         Thank you so much for your patience and be ready to show your friends these great shoes! Could you please show off your new designer perfume and be ready for tonight's fashion show?   \n",
       "18                                                                                                                                                                       The train is leaving and seat no. 11 is currently open.   \n",
       "19                                                                                                                                         The house was tidy, and the flowers had a good growing season. Thanks for helping me.   \n",
       "20                                                                                                                                                                                                              Talk now to Tom.   \n",
       "21                                                                                                                     The goal, which will be to organize the coins, is to sort any money from the piggy bank into small piles.   \n",
       "22                                                                                                                                                                                           If it's the truth, scream with joy.   \n",
       "23                                                                                                                                                                                        Introduce yourself, and a sip of wine.   \n",
       "24                                                                                                          When he arrives back at the office with the beer and rods, he would be happy to go fishing with Mark on the weekend.   \n",
       "\n",
       "    reward_before  \\\n",
       "0        1.386092   \n",
       "1        2.791882   \n",
       "2        2.459215   \n",
       "3        2.921001   \n",
       "4        1.903953   \n",
       "5        3.731444   \n",
       "6        3.724649   \n",
       "7        2.808177   \n",
       "8        0.279679   \n",
       "9        3.024493   \n",
       "10       3.503016   \n",
       "11       3.701590   \n",
       "12       3.762805   \n",
       "13       3.472419   \n",
       "14       2.966087   \n",
       "15       3.433033   \n",
       "16       2.229844   \n",
       "17       4.086845   \n",
       "18       4.065499   \n",
       "19       4.096716   \n",
       "20       1.994610   \n",
       "21       3.194796   \n",
       "22       2.619161   \n",
       "23       2.420433   \n",
       "24       3.896032   \n",
       "\n",
       "                                                                                                                                                                                                                                 response_after  \\\n",
       "0                                                                                                                                                                      The meeting starts at 12:00 today and before the clock strikes 12:30 pm.   \n",
       "1                                                     The party starts in evening at Person1's New House this Saturday. People are asking about some things to bring to the party that include apples, bananas, applesauce, and powdered sugar.   \n",
       "2                                                        Jane went to her uncle's farm three times, driving the tractor, taking care of the fruit garden, and teaching everyone. She also taught herself how to drive a lawn mower on the farm.   \n",
       "3                                     The entire family showed up on Time Night Thursday evening and were really excited for Ron and Ryan's bachelor's party tonight. They think Stanley is a really good singer. They'll move towards the ETV.   \n",
       "4                                                                                                                                                         #Person1#: I am a friend of Person2 so I need to know something about you and for me.   \n",
       "5                                                                                                                                         Officials at Uber and its sister company are meeting to cue the two about the status of the incident.   \n",
       "6                                                                                                                                                                                                   I'm very pleased with my stay in Edinburgh.   \n",
       "7                                                                                                                                                                                       #Person1: I am asked what e-card website are you using.   \n",
       "8                                                                                           Black people are extra welcome to the Mexican organization, CC. The group invites black sports fans to attend a disco party in the university club.   \n",
       "9                                                                                                                                                                                              Stay calm and explain exactly what is happening.   \n",
       "10                                                                                                                                                                                                     Primary class today is going to be busy.   \n",
       "11                                                                                                                                                                           #Person1#: Sorry to say we're running short. Are you ready to pay?   \n",
       "12                                                                                                              Check in with the train schedule and get a ticket. Catch a connecting train at the station, then travel down the West Turnpike.   \n",
       "13                                                                                                                                                                                                                        You are welcome, sir.   \n",
       "14                                                                                                                                                                                                                              Not good, Paul.   \n",
       "15                                                                                                                                                                                                             #Person1#: Thanks for your help.   \n",
       "16                                                                                                                                                                             The next time you're talking about unions, think about it again.   \n",
       "17                                                            #Parliament1: We are proud to welcome you to our Fashion Show. #Parliament2: We are making an invitation to all of our guests at our dressing rooms, Bellingham Hotel and Casino.   \n",
       "18                                                                                                                                                                                                                         Hamilton is waiting.   \n",
       "19                                                                                                                                                          From floor to ceiling, I can hear Jill and the neighbors whistling as Tom rolls in.   \n",
       "20                                                                                                                                                                                                       Tom will pick up Person1 at 6 o'clock.   \n",
       "21                                                                                                                                                                         Person1 will sort money into 6 piles with coins, quarters and dimes.   \n",
       "22                                                                                                                                                                                                                 #Person2: Thank you, Vivian.   \n",
       "23                                                                                                                                     #Person1#: Of course, Dinner is a bit expensive but once you get there, you still need to come prepared.   \n",
       "24  Everyone is complaining about the bill because someone else broke up with them this week. The bill was waiting for them so they could try to get together for some beer and water. Arky is going fishing so they should bring the sandbags.   \n",
       "\n",
       "    reward_after  reward_diff  \n",
       "0       3.388463     2.002372  \n",
       "1       3.583677     0.791795  \n",
       "2       3.215431     0.756216  \n",
       "3       3.626835     0.705834  \n",
       "4       2.565062     0.661109  \n",
       "5       4.277030     0.545586  \n",
       "6       4.097268     0.372619  \n",
       "7       3.116134     0.307957  \n",
       "8       0.579977     0.300298  \n",
       "9       3.267280     0.242787  \n",
       "10      3.734478     0.231462  \n",
       "11      3.755370     0.053780  \n",
       "12      3.814396     0.051591  \n",
       "13      3.438254    -0.034165  \n",
       "14      2.869358    -0.096729  \n",
       "15      3.320551    -0.112482  \n",
       "16      2.074817    -0.155027  \n",
       "17      3.922457    -0.164387  \n",
       "18      3.863837    -0.201662  \n",
       "19      3.873422    -0.223294  \n",
       "20      1.742499    -0.252111  \n",
       "21      2.906338    -0.288458  \n",
       "22      2.248540    -0.370621  \n",
       "23      1.989592    -0.430840  \n",
       "24      2.661874    -1.234158  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "df_compare_results = pd.DataFrame(compare_results)\n",
    "\n",
    "df_compare_results[\"reward_diff\"] = df_compare_results[\"reward_after\"] - df_compare_results[\"reward_before\"]\n",
    "\n",
    "df_compare_results_sorted = df_compare_results.sort_values(by=\"reward_diff\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "df_compare_results_sorted[[\n",
    "    \"query\",\n",
    "    \"response_before\", \"reward_before\",\n",
    "    \"response_after\", \"reward_after\",\n",
    "    \"reward_diff\"\n",
    "]]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
